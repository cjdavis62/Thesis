\chapter{Data Acquisition and Processing}
\label{ch:Data Acquisition and Processing}

While CUORE benefits from a relatively simplistic detection method compared with similar experiments in the field in that the experiment consists of effectively ~988 thermometers attached to a heat sink, converting these temperature readings to energy depositions is not a trivial process.
In particular, given that the NTDs have a strong dependence on the temperature, there are multiple sources of noise such as the pulse tubes, and data is being collected on nearly 1000 crystals simultaneously, collecting, processing, and optimizing this data requires automated and parallelizeable software procedures.

\section{CUORE Data Acquisition}
Because of the need in CUORE to calibrate $\sim$monthly, there are multiple layers for how data is organized for CUORE.
At the largest scales, there are datasets that begin and end during these monthly calibrations where the closing calibration for one dataset can be used as the opening calibration for the following dataset.
Composing each dataset are runs of $\sim24$ hour length.
These runs are further broken down into 3 types: `background' for physics runs, `calibration' for calibration runs, and `test' runs.
The test runs can be much more varied in duration than the ``standard" 24-hour background and calibration runs, and can include runs for various reasons, such as setting the working points of the NTDs or for scanning pulse tube phases.

At the smallest scales, the events on each detector are similar to that shown in \autoref{fig:Sample_pulse}.
These pulses occur with rise and fall times $\approx100$ ms and $\approx400$, respectively \cite{Alduino:2017ehq}.
A 10-second window (3 seconds before and 7 seconds after) is taken around these events to understand a stable bolometer temperature before and after the event, and the amplitude of the event is used to define the energy of the pulse.
The event rate per detector is $\approx 50$ mHz and $\approx6$ mHz in calibration\footnote{With the performance of the internal and external calibration systems, this rate can vary significantly on various towers and crystals.} and physics data, respectively.
In addition, as noted in \autoref{ssec:Particle Detection with Bolometers}, there are additional thermal pulses generated by the Si heater on the crystals occurring every few minutes.
While there is a software trigger applied on these events, which is discussed more in \autoref{sec:Online Data Taking}, there is no hardware trigger on these events.
This is due to the simplicity of the detection method in CUORE, in that the only signals are purely thermal and no precise ($\mathcal{O}(\mu~\textrm{s}$) timing is needed.
As a result, the data can be sampled continuously for each bolometer\footnote{Of the 988 CUORE bolometers, 4 observed an issue with the connections from the thermistor to the electronics after installation, and are unreadable.
The other bolometers have a connected signal to the NTD thermistor, while $\sim3\%$ of the 988 have non-functioning heaters.} at a rate of 1 kHz.

\section{Electronics Hardware and Detector Working Points}
\label{sec:Electronics Hardware}
On top of the Y-beam directly above the cryostat are the electronics hardware that reads out and biases the thermistor and Si heater electronic circuits.
These signals are carried up from the Cu-PEN tapes through the cryostat with twisted-pair constantan wires.
The NTDs are biased through two low-noise load resistors, and the voltage is measured by means of a low-noise room temperature preamplifier, a gain amplifier, and a 6-pole Thomson-Bessel low-pass filter \cite{doi:10.1063/1.4936269, PESSINA2000132, ARNABOLDI2010327}.
Lastly, these signals are digitized into a differential ADC\footnote{\RaggedRight NI PXI-6284: \url{http://sine.ni.com/nips/cds/view/p/lang/en/nid/201759}}
For each of the 988 bolometers in CUORE, the bias, gains, and offsets need to be tuned independently.
As one of the critical parameters for CUORE is the sensitivity at the \zeronubb~Q-value, maximizing the signal-to-noise ratios on each NTD is paramount.
This is achieved by first setting the bias on each of the NTDs.
At low bias, the signal amplitude depends linearly on the bias, but, at high bias, the temperature of the NTD increases, which affects the resistance and sensitivity of the NTD to signal.
In addition, different levels of bias induce various other effects on the noise, and the signal-to-noise ratio is not necessarily maximized when the amplitude is maximized.
In these scenarios, the bias is set to be when the SNR is maximized which is generally higher than the bias that maximizes the amplitude.
However, if the SNR is maximized, but a high bias makes the baseline unstable, the bias is instead lowered to the bias that maximizes the amplitude \cite{Lucia:LoadCurvesDoc}.
Following setting the bias for each channel, the gain and offset are then set for each channel such that a 2615 keV signal returns a 1-2 V amplitude and that events with energies up to 10-20 MeV can be recorded.
Given that the ADC range is -10 V to 10 V, an offset of $-4$ to $-7$ V is used which allows for the higher-energy events to be observed, while preventing a drifting baseline from saturating the ADC low.
This setting of bias, gain, and offset for each channel is called a working point, and these working points are generally held constant between datasets\footnote{In the event of a warm-up between datasets or in the case of changing the operating temperature of CUORE, these values need to be redetermined.}.

\section{Online Data Taking}
\label{sec:Online Data Taking}
The software used to collect the CUORE data is the \textsc{Apollo} software package that controls the working point setup and reading and triggering on data.
During data-taking, events can be categorized into three categories.
The first type of events are the physics events that consist of particles depositing energy in the crystals.
The second type of events are the heater pulses that occur on every channel every 380 seconds.
Lastly, the third type of events are noise events that occur without the presence of any significant energy deposition or Si heating. 
\subsection*{Signal Triggering}
There are two triggers used in CUORE to detect thermal events in the detectors.
The Derivative Trigger is the trigger used in standard analyses that triggers when the derivative of the baseline exceeds a certain threshold for long enough.
This threshold is set for each channel to be as low as possible before triggering excessively on noise events\footnote{If the threshold is set too low, this excessive event rate can crash the Data Acquisition System.
In addition, earthquakes can also cause the trigger to fire excessively and cause a crash.}, and, in addition, a 1 second dead time is placed on each channel before another signal may be triggered although a longer 10 second window is placed later on in the analysis.
These thresholds generally occur at $50-100$ keV per channel.
For triggering on lower-energy events, another trigger called Optimum Trigger is used, which utilizes a filtered waveform to reduce noise and suppress noise-induced pulse shapes that allows for $<10$ keV thresholds.
However, only the Derivative Trigger is used in this analysis as the events of interest occur at energies above 100 keV. 
These triggered events are classified then in three ways.
Firstly, the events that cause the Derivative Trigger to fire are labelled as the signal events described above.
For events that are due to the Si heaters on a channel, these are flagged by the software as \textsc{Apollo} reads that the pulsers are firing.
These events are also used as a test of the Derivative Trigger, as the efficiency of this trigger should be 1.
Lastly, the trigger also occurs on noise events.
This is done by triggering on every channel in a tower every 80-100 s.
These noise events allow for a measurement of the energy resolution at 0 keV, as no signal should be measured in these events.
In addition, these noise events allow for a measurement of the power spectrum of the noise on the detectors, and is what is minimized during a scan of the pulse tube phases.

\section{Offline Data Processing}
After the data are collected, the real work of processing can begin.
Again, all the data collected by CUORE directly comes in the form of an output voltage measured by the NTD.
The following processing steps are used to convert this data into a finalized format detailing the deposited energies of the particles that interact in the detectors, along with any associated energy depositions in other crystals, while optimizing signal resolution.
This processing is done with a special software developed for CUORE called \textsc{Diana} and is done in a set of ordered steps over all the triggered data.
First, the data is preprocessed to determine both the number of pulses in a trigger and the baseline slope in an event. 
Then the heights of the pulse peaks is determined and the baselines are stabilized.
Later, these stabilized amplitudes are mapped to a calibration spectrum and assigned an energy.
For energies near the \zeronubb Q-value, and 2615 keV peak, these energies are also salted and blinded in the \zeronubb~analysis.

\subsection*{First-Level Processing}
The first level of processing involves the steps required to assign energies to the pulses and then the blinding of the \zeronubb~ROI.
While this blinding is applied in every step of the analysis chain, this blinding procedure is not performed for the background model and Majoron searches, and will not be discussed in this thesis.
\subsubsection*{Bad Intervals}
Firstly, after the data is collected by \textsc{Apollo}, bad intervals are then applied to the data to subtract out times when the data are noisy or otherwise unsuitable for analysis, such as when the baselines saturate low or high, when a mechanical or electronic malfunction causes instability of the detector baseline, or during an earthquake.
Depending on the source of the issue, these bad intervals can be set channel-by-channel or detector-wide, and can be set either by an automatic tool that detects these times, or manually by an analysis shifter.
\subsubsection*{Preprocess}
We prepare stuff for real processing
\subsubsection*{Amplitude Evaluation}
We calculate the height of the peaks
\subsubsection*{Stabilization}
Need to stabilize at different baselines
\label{ssec:Stabilization}

The energy dissipated in the silicon heater transfers into the bolometer similarly how a real energy deposition would look in a physics event, and allows for us to understand the response of the detector to fixed-energy input across various detector baselines as the temperature of the detectors drifts \cite{ALESSANDRELLO1998454:Si-heater}.

\subsubsection{Calibration}
How do we tell that different calibration rates are correct?
\label{ssec:Calibration}
\subsection{Second-Level Processing}
\subsubsection{Pulse Shape Analysis}
\subsubsection{Coincidence Analysis}



